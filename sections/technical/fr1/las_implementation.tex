% corrected VD 99

\subsubsection{FR01: Presentation of an existing LAS implementation.}

In this section, the PyTorch implementation of the LAS end-to-end\cite{alex2019sequencetosequence} ASR system is presented. The main entry of this implementation is the \textit{main.py} program:

\lstinputlisting{sections/technical/fr1/las_main.py}

The \textit{main.py} imports the class \textit{Solver} from \textit{bin.train\_asr} while being in the training mode. An instance of the Solver class is created with the hyperparameters and training mode as arguments line 20). This object loads the training and validation set with the \textit{load\_data()} method (line 21). The object initialises a model with the defined hyperparameters with the \textit{set\_model()} method (line 22) and executes its training with the method \textit{exec()} (line 23).\\

In the following listing, the method \textit{load\_data()} is shown:

\lstinputlisting{sections/technical/fr1/las_load_data.py}

The function \textit{load\_dataset()} uses PyTorch's DataLoader interface which is an utility to customize loading of datasets (line 3). This function parses the LibriSpeech dataset, extracts the Mel-filterbanks and outputs the training and the validation sets divided into batches.\\

The following listing showcases the \textit{set\_model()} method, which initialises the \textit{Adadelta} optimizer, creates an \textit{ASR()} instance for the \textit{self.model} attribute and asigns the \textit{CrossEntropyLoss} as the loss function.

\lstinputlisting{sections/technical/fr1/las_set_model.py}

The \textit{ASR()} class is defined as follows:

\lstinputlisting{sections/technical/fr1/las_asr_class.py}

When initializing the \textit{ASR()} class, it creates an encoder layer, an Embedding layer for the vocabulary, a dropout layer, a decoder layer and an attention layer.\\

The \textit{exec()} method is defined as follows:

\lstinputlisting{sections/technical/fr1/las_exec.py}

This function trains the model initialized in the previous steps. The model passes the input data forward through the network with the method \textit{self.model()}, propagates the losses back with the method \textit{self.backward(total\_loss)} and increments the number of steps by one. The function calls the methods \textit{self.log()} and \textit{self.validate()} to log the current training state and validate the model's performance respectively.
