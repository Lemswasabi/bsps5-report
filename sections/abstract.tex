% corrected VD 93

\begin{abstract}

	\textbf{\color{red}{Not finale version.}} Deep Neural Networks (DNNs) improved many
	components of speech recognizers.  They are commonly used in the DNN-Hidden
	Markov model (DNN-HMM) based speech recognition systems for acoustic
	modelling. Traditionally these components, such as acoustic, pronunciation
	and language models, have all been trained separately with different
	objectives. Recent work in this area tries to solve this disjoint training
	issue by creating models that are trained end-to-end, in other words,
	converting speech directly to transcripts. Unlike traditional DNN-HMM models,
	the attention-based model learns all the components of a speech recognizer
	jointly. This system has two components: a listener and a speller. The
	listener is a recurrent neural network encoder which processes filter bank
	spectra. The spelling component is an attention-based recurrent network
	decoder which outputs characters.

\end{abstract}
